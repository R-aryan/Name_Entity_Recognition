{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Medical",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6f+wycHxrwqj6flT7LG3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-aryan/Name_Entity_Recognition/blob/master/NER_Medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viEoK2jE0s73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkZZWACG03TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXSHW446039Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGH_DFMs1ODX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import unicodedata\n",
        " \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "from keras.layers import TimeDistributed, Dropout, Bidirectional\n",
        " \n",
        "# Defining Constants\n",
        " \n",
        "# Maximum length of text sentences\n",
        "MAXLEN = 180\n",
        "# Number of LSTM units\n",
        "LSTM_N = 150\n",
        "# batch size\n",
        "BS=48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0JkJUI_1QGf",
        "colab_type": "code",
        "outputId": "5d59afc5-7eb7-4b2f-97bf-5d778e1457b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/NER_Disease/train.csv\", encoding=\"latin1\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Doc_ID</th>\n",
              "      <th>Sent_ID</th>\n",
              "      <th>Word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Obesity</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Low-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Middle-Income</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Doc_ID  Sent_ID           Word tag\n",
              "0   1       1        1        Obesity   O\n",
              "1   2       1        1             in   O\n",
              "2   3       1        1           Low-   O\n",
              "3   4       1        1            and   O\n",
              "4   5       1        1  Middle-Income   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOSxuu281Xfi",
        "colab_type": "code",
        "outputId": "afabcc24-cd32-4bc3-8277-accc2a3b3157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "test_data = pd.read_csv(\"/content/drive/My Drive/NER_Disease/test.csv\", encoding=\"latin1\")\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Doc_ID</th>\n",
              "      <th>Sent_ID</th>\n",
              "      <th>Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4543834</td>\n",
              "      <td>30001</td>\n",
              "      <td>191283</td>\n",
              "      <td>CCCVA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4543835</td>\n",
              "      <td>30001</td>\n",
              "      <td>191283</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4543836</td>\n",
              "      <td>30001</td>\n",
              "      <td>191283</td>\n",
              "      <td>MANOVA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4543837</td>\n",
              "      <td>30001</td>\n",
              "      <td>191283</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4543838</td>\n",
              "      <td>30001</td>\n",
              "      <td>191283</td>\n",
              "      <td>my</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  Doc_ID  Sent_ID    Word\n",
              "0  4543834   30001   191283   CCCVA\n",
              "1  4543835   30001   191283       ,\n",
              "2  4543836   30001   191283  MANOVA\n",
              "3  4543837   30001   191283       ,\n",
              "4  4543838   30001   191283      my"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgBu6BB01mxV",
        "colab_type": "code",
        "outputId": "5e1be5d0-5288-4dfe-e1ef-94e7dca55e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(data['tag'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O' 'B-indications' 'I-indications']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65JF-IjU1r-t",
        "colab_type": "text"
      },
      "source": [
        "Creating Word & Tag dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obtw9dEr1szU",
        "colab_type": "code",
        "outputId": "687cabf4-7545-4e6c-c1a9-350924862115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "print(\"Number of uniques docs, sentences and words in Training set:\\n\",data.nunique())\n",
        "print(\"\\nNumber of uniques docs, sentences and words in Test set:\\n\",test_data.nunique())\n",
        " \n",
        "# Creating a vocabulary\n",
        "words = list(set(data[\"Word\"].append(test_data[\"Word\"]).values))\n",
        "words.append(\"ENDPAD\")\n",
        " \n",
        "# Converting greek characters to ASCII characters eg. 'naïve café' to 'naive cafe'\n",
        "words = [unicodedata.normalize('NFKD', str(w)).encode('ascii','ignore') for w in words]\n",
        "n_words = len(words)\n",
        "print(\"\\nLength of vocabulary = \",n_words)\n",
        " \n",
        "tags = list(set(data[\"tag\"].values))\n",
        "n_tags = len(tags)\n",
        "print(\"\\nnumber of tags = \",n_tags)\n",
        " \n",
        "# Creating words to indices dictionary.\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "# Creating tags to indices dictionary.\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of uniques docs, sentences and words in Training set:\n",
            " id         4543833\n",
            "Doc_ID       30000\n",
            "Sent_ID     191282\n",
            "Word        184505\n",
            "tag              3\n",
            "dtype: int64\n",
            "\n",
            "Number of uniques docs, sentences and words in Test set:\n",
            " id         2994463\n",
            "Doc_ID       20000\n",
            "Sent_ID     125840\n",
            "Word        139891\n",
            "dtype: int64\n",
            "\n",
            "Length of vocabulary =  257203\n",
            "\n",
            "number of tags =  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVNyG8UP1xeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwodgApe12bR",
        "colab_type": "text"
      },
      "source": [
        " Getting Train & Test Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvSovfHi13GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tagged_sentences(data):\n",
        "\n",
        "\n",
        "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(), s[\"tag\"].values.tolist())]\n",
        "    grouped = data.groupby(\"Sent_ID\").apply(agg_func)\n",
        "    sentences = [s for s in grouped]\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def get_test_sentences(data):\n",
        "\n",
        "    agg_func = lambda s: [w for w in s[\"Word\"].values.tolist()]\n",
        "    grouped = data.groupby(\"Sent_ID\").apply(agg_func)\n",
        "    sentences = [s for s in grouped]\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFrDX9oH18SA",
        "colab_type": "code",
        "outputId": "76e9df31-5070-452b-f160-f0c43a9b0c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Getting training sentences in a list\n",
        "sentences = get_tagged_sentences(data)\n",
        "print(\"First 2 sentences in a word list format:\\n\",sentences[0:2])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 2 sentences in a word list format:\n",
            " [[('Obesity', 'O'), ('in', 'O'), ('Low-', 'O'), ('and', 'O'), ('Middle-Income', 'O'), ('Countries', 'O'), (':', 'O'), ('Burden', 'O'), (',', 'O'), ('Drivers', 'O'), (',', 'O'), ('and', 'O'), ('Emerging', 'O'), ('Challenges', 'O'), ('.', 'O')], [('We', 'O'), ('have', 'O'), ('reviewed', 'O'), ('the', 'O'), ('distinctive', 'O'), ('features', 'O'), ('of', 'O'), ('excess', 'O'), ('weight', 'O'), (',', 'O'), ('its', 'O'), ('causes', 'O'), (',', 'O'), ('and', 'O'), ('related', 'O'), ('prevention', 'O'), ('and', 'O'), ('management', 'O'), ('efforts', 'O'), (',', 'O'), ('as', 'O'), ('well', 'O'), ('as', 'O'), ('data', 'O'), ('gaps', 'O'), ('and', 'O'), ('recommendations', 'O'), ('for', 'O'), ('future', 'O'), ('research', 'O'), ('in', 'O'), ('low-', 'O'), ('and', 'O'), ('middle-income', 'O'), ('countries', 'O'), ('(', 'O'), ('LMICs', 'O'), (')', 'O'), ('.', 'O')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH5Yf7ee2lLh",
        "colab_type": "code",
        "outputId": "abed0c37-edf1-48e7-944d-caceba4085d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Getting test sentences in a list\n",
        "test_sentences = get_test_sentences(test_data)\n",
        "print(\"First 2 sentences in a word list format:\\n\",test_sentences[0:2])\n",
        "print(type(test_sentences))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 2 sentences in a word list format:\n",
            " [['CCCVA', ',', 'MANOVA', ',', 'my', 'black', 'hen', '.'], ['Comments', 'on', 'repeated', 'measures', '.']]\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4RxbFHe2u-t",
        "colab_type": "code",
        "outputId": "84140551-775b-4e14-c8b1-4c00444a746f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "X_test = [[word2idx[unicodedata.normalize('NFKD', str(w)).\n",
        "encode('ascii','ignore')] for w in s] for s in test_sentences]\n",
        "\n",
        "print(words[1:10])\n",
        "\n",
        "print(type(X_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'VPDs', b'0.14-0.87', b'facilitated-diffusion', b'Powassan', b'alpha-monoclonal', b'HHHFNCT', b'decentralize', b'1A135', b'plasmid-derived']\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB1x5xsU28Xr",
        "colab_type": "text"
      },
      "source": [
        "Feature Extraction for DL Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4qVyFGw28_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting words to indices for test sentences (Features)\n",
        "# Converting greek characters to ASCII characters in train set eg. 'naïve café' to 'naive cafe'\n",
        "X = [[word2idx[unicodedata.normalize('NFKD', str(w[0])).\n",
        "encode('ascii','ignore')] for w in s] for s in sentences]\n",
        " \n",
        "# Converting words to indices for test sentences (Features)\n",
        "# Converting greek characters to ASCII characters in test-set eg. 'naïve café' to 'naive cafe'\n",
        "X_test = [[word2idx[unicodedata.normalize('NFKD', str(w)).\n",
        "encode('ascii','ignore')] for w in s] for s in test_sentences]\n",
        " \n",
        "'''\n",
        "Padding train and test sentences to 180 words.\n",
        "Sentences of length greater than 180 words are truncated.\n",
        "Sentences of length less than 180 words are padded with a high value.\n",
        "'''\n",
        "X = pad_sequences(maxlen=MAXLEN, sequences=X, padding=\"post\", value=n_words - 1)\n",
        "X_test = pad_sequences(maxlen=MAXLEN, sequences=X_test, padding=\"post\", value=n_words - 1)\n",
        " \n",
        "# Converting tags to indices for test sentences (labels)\n",
        "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "# Padding tag labels to 180 words.\n",
        "y = pad_sequences(maxlen=MAXLEN, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
        " \n",
        "# Making labels in one hot encoded form for DL model\n",
        "y = [to_categorical(i, num_classes=n_tags) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei_Rs4LH3AMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjcr7qft3GMk",
        "colab_type": "text"
      },
      "source": [
        "Building  Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r9vQSgJ3Iko",
        "colab_type": "code",
        "outputId": "8603b50d-5796-4305-b6a5-a6737896a98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "# 180 dimensional word indices as input\n",
        "input = Input(shape=(MAXLEN,))\n",
        " \n",
        "# Embedding layer of same length output (180 dim embedding will be generated)\n",
        "model = Embedding(input_dim=n_words, output_dim=MAXLEN, input_length=MAXLEN)(input)\n",
        " \n",
        "# Adding dropout layer\n",
        "model = Dropout(0.2)(model)\n",
        " \n",
        "# Bidirectional LSTM to learn from both forward as well as backward context\n",
        "model = Bidirectional(LSTM(units=LSTM_N, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        " \n",
        "# Adding a TimeDistributedDense, to applying a Dense layer on each 180 timesteps\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model) # softmax output layer\n",
        "model = Model(input, out)\n",
        " \n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X, np.array(y), batch_size=BS, epochs=2, validation_split=0.05, verbose=1)\n",
        "\n",
        "model.save('/content/drive/My Drive/NER_Disease/my_NER_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 181717 samples, validate on 9565 samples\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "181717/181717 [==============================] - 2320s 13ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9988\n",
            "Epoch 2/2\n",
            "181717/181717 [==============================] - 2304s 13ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0038 - val_acc: 0.9989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQYTpYYa3L4C",
        "colab_type": "code",
        "outputId": "c22d351d-9ace-46f3-a975-165240346e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 180, 180)          46296540  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 180, 180)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 180, 300)          397200    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 180, 3)            903       \n",
            "=================================================================\n",
            "Total params: 46,694,643\n",
            "Trainable params: 46,694,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG_eUjPQHvvd",
        "colab_type": "text"
      },
      "source": [
        "Prediction on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBsqju3pjECO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QK5vTqjMlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/NER_Disease/my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GneTL0Y9Hwjl",
        "colab_type": "code",
        "outputId": "f4fa0fcd-323d-4eff-e304-87a4ad1ff5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Predicting on trained model\n",
        "pred = model.predict(X_test)\n",
        "print(\"Predicted Probabilities on Test Set:\\n\",pred.shape)\n",
        "# taking tag class with maximum probability\n",
        "pred_index = np.argmax(pred, axis=-1)\n",
        "print(\"Predicted tag indices: \\n\",pred_index.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Probabilities on Test Set:\n",
            " (125840, 180, 3)\n",
            "Predicted tag indices: \n",
            " (125840, 180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsHNzq83jLBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDOo3NMFH2GA",
        "colab_type": "code",
        "outputId": "26b78e03-3c08-499f-e5ef-83c265e231fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Flatten both the features and predicted tags\n",
        "ids,tagids = X_test.flatten().tolist(), pred_index.flatten().tolist()\n",
        " \n",
        "# converting each word indices back to words\n",
        "words_test = [words[ind].decode('utf-8') for ind in ids]\n",
        "# converting each predicted tag indices back to tags\n",
        "tags_test = [tags[ind] for ind in tagids]\n",
        "print(\"Length of words in Padded test set:\",len(words_test))\n",
        "print(\"Length of tags in Padded test set:\",len(tags_test))\n",
        "print(\"\\nCheck few of words and predicted tags:\\n\",words_test[:10],tags_test[:10])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of words in Padded test set: 22651200\n",
            "Length of tags in Padded test set: 22651200\n",
            "\n",
            "Check few of words and predicted tags:\n",
            " ['CCCVA', ',', 'MANOVA', ',', 'my', 'black', 'hen', '.', 'ENDPAD', 'ENDPAD'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAnbgA4bOnkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/My Drive/NER_Disease/my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAj-P5zyPguY",
        "colab_type": "code",
        "outputId": "e58f31d5-c142-4f98-d5aa-fc3d44997939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "'''\n",
        "The task here is to convert padded fixed 180 dimensional predicted tags\n",
        "to variable length test set sentences.\n",
        "1. If the sentences have word length shorter than 180,\n",
        "   then predcited tags are skipped.\n",
        "2. If the sentences have word length longer than 180,\n",
        "   then all extra words are tagged with \"O\" tag class.\n",
        "'''\n",
        " \n",
        "i=0\n",
        "j=1\n",
        "predicted_tags = []\n",
        "predicted_words=[]\n",
        "counts = test_data.groupby('Sent_ID')['id'].count().tolist()\n",
        " \n",
        "for index,count in enumerate(counts):\n",
        "    if count <= MAXLEN:\n",
        "        predicted_tags.append(tags_test[i:i+count])\n",
        "        predicted_words.append(words_test[i:i+count])\n",
        "    else:\n",
        "        predicted_tags.append(tags_test[i:i+MAXLEN])\n",
        "        predicted_words.append(words_test[i:i+MAXLEN])\n",
        "        out = ['O']*(count-MAXLEN)\n",
        "        predicted_tags.append(out)\n",
        "        predicted_words.append(out)\n",
        " \n",
        "    i=j*MAXLEN\n",
        "    j=j+1\n",
        " \n",
        "predictions_final = [item for sublist in predicted_tags for item in sublist]\n",
        "words_final = [item for sublist in predicted_words for item in sublist]\n",
        "print(\"\\nLength of test set words and predicted tags should match.\")\n",
        "print(\"Length of predicted tags:\",len(predictions_final))\n",
        "print(\"Length of words in test set:\",test_data['Word'].size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of test set words and predicted tags should match.\n",
            "Length of predicted tags: 2994463\n",
            "Length of words in test set: 2994463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtUZiLglPqt-",
        "colab_type": "code",
        "outputId": "80276fa5-3124-4266-f0e4-a449bd06afa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "#df = pd.read_csv(\"/content/drive/My Drive/NER_Disease/sample_submission.csv\", encoding=\"latin1\")\n",
        "# Creating a dataframe in the submission format\n",
        "df_results = pd.DataFrame({'word':words_final,'tag':predictions_final})\n",
        "# writing csv submission file\n",
        "df_results.to_csv('/content/drive/My Drive/NER_Disease/prediction_final.csv',sep=\",\", index=None)\n",
        "df_results.head(17)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCVA</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MANOVA</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>my</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>black</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hen</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Comments</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>on</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>repeated</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>measures</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Nikolsky</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sign</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>;</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>page</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word tag\n",
              "0      CCCVA   O\n",
              "1          ,   O\n",
              "2     MANOVA   O\n",
              "3          ,   O\n",
              "4         my   O\n",
              "5      black   O\n",
              "6        hen   O\n",
              "7          .   O\n",
              "8   Comments   O\n",
              "9         on   O\n",
              "10  repeated   O\n",
              "11  measures   O\n",
              "12         .   O\n",
              "13  Nikolsky   O\n",
              "14      sign   O\n",
              "15         ;   O\n",
              "16      page   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShJ9GBNYTZ0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def predict_output(X_test,words):\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#   # Predicting on trained model\n",
        "#   pred = model.predict(X_test)\n",
        "#   print(\"Predicted Probabilities on Test Set:\\n\",pred.shape)\n",
        "#   # taking tag class with maximum probability\n",
        "#   pred_index = np.argmax(pred, axis=-1)\n",
        "#   print(\"Predicted tag indices: \\n\",pred_index.shape)\n",
        "\n",
        "\n",
        "#   # Flatten both the features and predicted tags\n",
        "#   ids,tagids = X_test.flatten().tolist(), pred_index.flatten().tolist()\n",
        " \n",
        "#   # converting each word indices back to words\n",
        "#   words_test = [words[ind].decode('utf-8') for ind in ids]\n",
        "#   # converting each predicted tag indices back to tags\n",
        "#   tags_test = [tags[ind] for ind in tagids]\n",
        "#   #print(tagids)\n",
        "#   print(\"Length of words in Padded test set:\",len(words_test))\n",
        "#   print(\"Length of tags in Padded test set:\",len(tags_test))\n",
        "#   print(\"\\nCheck few of words and predicted tags:\\n\",words_test[:10],tags_test[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTP6J_AzZ2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def convert_input(str_test):\n",
        "\n",
        "\n",
        "#   # doc = nlp(str_test)\n",
        "#   # print(doc.ents)\n",
        " \n",
        "\n",
        "#   str_test = list(str_test.split())\n",
        " \n",
        "\n",
        "#   words= list(set(str_test))\n",
        "\n",
        "#   words.append(\"ENDPAD\")\n",
        "\n",
        "#   n_words = len(words)\n",
        "\n",
        "#   words= [unicodedata.normalize('NFKD', str(w)).encode('ascii','ignore') for w in words]\n",
        "\n",
        "#   # Creating words to indices dictionary.\n",
        "#   word2idx = {w: i for i, w in enumerate(words)}\n",
        "\n",
        "#   X_test = [[word2idx[unicodedata.normalize('NFKD', str(w)).encode('ascii','ignore')] for w in str_test]]\n",
        "\n",
        "#   X_test = pad_sequences(maxlen=MAXLEN, sequences=X_test, padding=\"post\", value=n_words - 1)\n",
        "\n",
        "#   predict_output(X_test,words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Ib6e0jzqji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqGoWUomzwPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}